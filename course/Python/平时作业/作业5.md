# Python第5次作业

继续使用"数据12.1"，以总店数、年末从业人数、年末餐饮营业面积、统一配送商品购进额4个变量，即V2、V4、V5、V9，对所有样本观测值开展划分聚类分析和层次聚类分析。

1. 载入分析所需要的库和模块
2. 变量设置及数据处理
3. 特征变量相关性分析
4. 使用K均值聚类分析方法对样本示例进行聚类(K=2)
5. 使用K均值聚类分析方法对样本示例进行聚类(K=3)
6. 使用K均值聚类分析方法对样本示例进行聚类(K=4)


## 1. 载入分析所需要的库和模块


```python
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
```

---

## 2. 变量设置及数据处理


```python
data = pd.read_csv('../data/数据12.1.csv')
X = data.iloc[:, [1,3,4,8]]
X.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 28 entries, 0 to 27
    Data columns (total 4 columns):
     #   Column  Non-Null Count  Dtype  
    ---  ------  --------------  ------
     0   V2      28 non-null     int64  
     1   V4      28 non-null     float64
     2   V5      28 non-null     float64
     3   V9      28 non-null     float64
    dtypes: float64(3), int64(1)
    memory usage: 1.0 KB

数据共包含28个样本，4个特征变量。其中V2（总店数）为整数类型，V4（年末从业人数）、V5（年末餐饮营业面积）和V9（统一配送商品购进额）为浮点数类型。所有变量均无缺失值。

```python
len(X.columns)
```

    4

确认数据集包含4个特征变量，与作业要求一致。

```python
X.columns
```

    Index(['V2', 'V4', 'V5', 'V9'], dtype='object')

特征变量名称分别为V2、V4、V5、V9，对应题目要求的总店数、年末从业人数、年末餐饮营业面积和统一配送商品购进额。

```python
X.shape
```

    (28, 4)

数据集维度为28行4列，即28个样本观测值和4个特征变量。

```python
X.dtypes
```

    V2      int64
    V4    float64
    V5    float64
    V9    float64
    dtype: object

进一步确认各变量的数据类型，V2为整数型，其余三个变量为浮点型。

```python
X.isnull().values.any()
```

    np.False_

数据集不存在任何缺失值，返回结果为False。

```python
X.isnull().sum()
```

    V2    0
    V4    0
    V5    0
    V9    0
    dtype: int64

详细统计每个变量的缺失值数量，所有变量均无缺失值。

```python
X.head(10)
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V2</th>
      <th>V4</th>
      <th>V5</th>
      <th>V9</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>95</td>
      <td>16.3</td>
      <td>240.8</td>
      <td>152.28</td>
    </tr>
    <tr>
      <th>1</th>
      <td>9</td>
      <td>3.5</td>
      <td>25.9</td>
      <td>5.13</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5</td>
      <td>0.1</td>
      <td>4.1</td>
      <td>0.61</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>0.5</td>
      <td>4.1</td>
      <td>3.63</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3</td>
      <td>0.3</td>
      <td>6.5</td>
      <td>0.12</td>
    </tr>
    <tr>
      <th>5</th>
      <td>13</td>
      <td>1.6</td>
      <td>35.6</td>
      <td>52.85</td>
    </tr>
    <tr>
      <th>6</th>
      <td>4</td>
      <td>0.2</td>
      <td>2.9</td>
      <td>1.20</td>
    </tr>
    <tr>
      <th>7</th>
      <td>18</td>
      <td>5.6</td>
      <td>52.2</td>
      <td>23.56</td>
    </tr>
    <tr>
      <th>8</th>
      <td>31</td>
      <td>4.9</td>
      <td>68.3</td>
      <td>34.52</td>
    </tr>
    <tr>
      <th>9</th>
      <td>8</td>
      <td>1.7</td>
      <td>19.9</td>
      <td>9.77</td>
    </tr>
  </tbody>
</table>
</div>

展示了数据集的前10个样本，可以观察到各变量的取值范围差异较大。例如，第一个样本（索引0）的V2（总店数）为95，远高于其他样本；V9（统一配送商品购进额）也显示出类似的数量级差异。

```python
scaler = StandardScaler()
scaler.fit(X)
X_s = scaler.transform(X)
X_s = pd.DataFrame(X_s, columns=X.columns)
X_s
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V2</th>
      <th>V4</th>
      <th>V5</th>
      <th>V9</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3.331341</td>
      <td>2.770017</td>
      <td>3.405459</td>
      <td>3.989002</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.373910</td>
      <td>0.034349</td>
      <td>-0.259663</td>
      <td>-0.452757</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.546248</td>
      <td>-0.692313</td>
      <td>-0.631462</td>
      <td>-0.589194</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.589332</td>
      <td>-0.606824</td>
      <td>-0.631462</td>
      <td>-0.498035</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.632416</td>
      <td>-0.649569</td>
      <td>-0.590530</td>
      <td>-0.603985</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.201573</td>
      <td>-0.371727</td>
      <td>-0.094229</td>
      <td>0.987683</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-0.589332</td>
      <td>-0.670941</td>
      <td>-0.651928</td>
      <td>-0.571385</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.013849</td>
      <td>0.483169</td>
      <td>0.188884</td>
      <td>0.103557</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.573945</td>
      <td>0.333562</td>
      <td>0.463470</td>
      <td>0.434387</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-0.416995</td>
      <td>-0.350355</td>
      <td>-0.361993</td>
      <td>-0.312698</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.229270</td>
      <td>-0.072514</td>
      <td>-0.269896</td>
      <td>-0.255044</td>
    </tr>
    <tr>
      <th>11</th>
      <td>-0.589332</td>
      <td>-0.628196</td>
      <td>-0.597352</td>
      <td>-0.399631</td>
    </tr>
    <tr>
      <th>12</th>
      <td>-0.029236</td>
      <td>-0.243493</td>
      <td>0.035389</td>
      <td>-0.134303</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-0.158489</td>
      <td>-0.564079</td>
      <td>-0.553009</td>
      <td>-0.507091</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.703198</td>
      <td>0.012976</td>
      <td>0.158185</td>
      <td>0.056770</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.013849</td>
      <td>0.183955</td>
      <td>0.214467</td>
      <td>-0.121625</td>
    </tr>
    <tr>
      <th>16</th>
      <td>-0.589332</td>
      <td>-0.499962</td>
      <td>-0.566653</td>
      <td>-0.470868</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-0.718585</td>
      <td>-0.713686</td>
      <td>-0.696271</td>
      <td>-0.599156</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-0.244657</td>
      <td>0.162583</td>
      <td>0.402072</td>
      <td>-0.220029</td>
    </tr>
    <tr>
      <th>19</th>
      <td>-0.330826</td>
      <td>0.483169</td>
      <td>0.224700</td>
      <td>-0.214897</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.675501</td>
      <td>-0.713686</td>
      <td>-0.672394</td>
      <td>-0.600967</td>
    </tr>
    <tr>
      <th>21</th>
      <td>-0.546248</td>
      <td>-0.564079</td>
      <td>-0.605879</td>
      <td>-0.522183</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-0.718585</td>
      <td>-0.713686</td>
      <td>-0.699682</td>
      <td>-0.603080</td>
    </tr>
    <tr>
      <th>23</th>
      <td>-0.330826</td>
      <td>-0.371727</td>
      <td>-0.430213</td>
      <td>-0.296699</td>
    </tr>
    <tr>
      <th>24</th>
      <td>-0.632416</td>
      <td>-0.649569</td>
      <td>-0.665572</td>
      <td>-0.551463</td>
    </tr>
    <tr>
      <th>25</th>
      <td>-0.546248</td>
      <td>-0.649569</td>
      <td>-0.633167</td>
      <td>-0.525202</td>
    </tr>
    <tr>
      <th>26</th>
      <td>1.952643</td>
      <td>2.684527</td>
      <td>2.279828</td>
      <td>1.284706</td>
    </tr>
    <tr>
      <th>27</th>
      <td>2.641992</td>
      <td>2.577665</td>
      <td>2.238896</td>
      <td>2.194187</td>
    </tr>
  </tbody>
</table>
</div>

通过StandardScaler将所有特征变量转换为均值为0、标准差为1的标准化数据。可以看到，第一个样本（索引0）的各项指标仍保持较高的标准化值（约2.77-3.99之间），而其他样本则分布在-0.7到0.7的范围内。标准化后的数据更适合进行聚类分析，可以避免因变量量级差异导致的聚类结果偏差。

---

## 3. 特征变量相关性分析


```python
print(X_s.corr(method='pearson'))
```

              V2        V4        V5        V9
    V2  1.000000  0.946057  0.966842  0.938237
    V4  0.946057  1.000000  0.977966  0.879125
    V5  0.966842  0.977966  1.000000  0.938684
    V9  0.938237  0.879125  0.938684  1.000000

相关性分析结果显示，所有特征变量之间存在高度正相关关系。相关系数均在0.87以上，其中V4和V5的相关系数最高（0.977966），表明年末从业人数和年末餐饮营业面积之间存在极强的线性关系。V2（总店数）与V5（年末餐饮营业面积）的相关系数也很高（0.966842）。

```python
plt.subplot(1,1,1)
sns.heatmap(X_s.corr(), annot=True)
```

![png](image/%E4%BD%9C%E4%B8%9A5_15_1.png)

热力图直观展示了各变量间的相关系数。颜色深浅表示相关程度，越接近红色表示相关性越强。图中对角线为自相关系数1，其他格子中的数字即为相关系数值。

---

## 4. K均值聚类分析

### 4.1 对样本示例进行聚类(K=2)


```python
model = KMeans(n_clusters=2, random_state=2)
model.fit(X_s)
model.labels_
```

    array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
           0, 0, 0, 0, 1, 1], dtype=int32)

使用K=2的K均值聚类算法完成了对28个样本的聚类。结果显示，大部分样本（25个）被分到第0类，只有3个样本（索引0、26、27）被分到第1类。这表明数据中存在明显的少数离群点或特殊群体。

```python
pd.DataFrame(model.labels_.T, index=data.V1,columns=['聚类'])
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>聚类</th>
    </tr>
    <tr>
      <th>V1</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>北京</th>
      <td>1</td>
    </tr>
    <tr>
      <th>天津</th>
      <td>0</td>
    </tr>
    <tr>
      <th>河北</th>
      <td>0</td>
    </tr>
    <tr>
      <th>山西</th>
      <td>0</td>
    </tr>
    <tr>
      <th>内蒙古</th>
      <td>0</td>
    </tr>
    <tr>
      <th>辽宁</th>
      <td>0</td>
    </tr>
    <tr>
      <th>黑龙江</th>
      <td>0</td>
    </tr>
    <tr>
      <th>江苏</th>
      <td>0</td>
    </tr>
    <tr>
      <th>浙江</th>
      <td>0</td>
    </tr>
    <tr>
      <th>安徽</th>
      <td>0</td>
    </tr>
    <tr>
      <th>福建</th>
      <td>0</td>
    </tr>
    <tr>
      <th>江西</th>
      <td>0</td>
    </tr>
    <tr>
      <th>山东</th>
      <td>0</td>
    </tr>
    <tr>
      <th>河南</th>
      <td>0</td>
    </tr>
    <tr>
      <th>湖北</th>
      <td>0</td>
    </tr>
    <tr>
      <th>湖南</th>
      <td>0</td>
    </tr>
    <tr>
      <th>广西</th>
      <td>0</td>
    </tr>
    <tr>
      <th>海南</th>
      <td>0</td>
    </tr>
    <tr>
      <th>重庆</th>
      <td>0</td>
    </tr>
    <tr>
      <th>四川</th>
      <td>0</td>
    </tr>
    <tr>
      <th>贵州</th>
      <td>0</td>
    </tr>
    <tr>
      <th>云南</th>
      <td>0</td>
    </tr>
    <tr>
      <th>西藏</th>
      <td>0</td>
    </tr>
    <tr>
      <th>陕西</th>
      <td>0</td>
    </tr>
    <tr>
      <th>甘肃</th>
      <td>0</td>
    </tr>
    <tr>
      <th>新疆</th>
      <td>0</td>
    </tr>
    <tr>
      <th>上海</th>
      <td>1</td>
    </tr>
    <tr>
      <th>广东</th>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>

按省份名称显示聚类结果，可以清晰看到第1类包含北京、上海和广东三个地区，其他25个地区属于第0类。这表明在商业规模（总店数、从业人数、营业面积和配送额）方面，北京、上海和广东明显领先于其他地区，形成了一个高规模的特殊群体。

```python
model.cluster_centers_
```

    array([[-0.31703902, -0.32128836, -0.31696734, -0.29871581],
           [ 2.64199186,  2.67740299,  2.64139452,  2.48929838]])

展示了两个聚类中心的坐标。第0类的中心坐标全部为负值，而第1类的中心坐标全部为较大的正值（约2.49-2.68之间）。这进一步证实了两类之间存在显著差异，第1类（北京、上海、广东）在所有标准化特征上都远高于平均水平，而第0类则略低于平均水平。

```python
model.inertia_
```

    20.197477847186683

聚类的惯性（inertia）值为20.197，这是各样本到其所属聚类中心距离的平方和。该值反映了聚类的紧密程度，值越小表示聚类效果越好。

### 4.2 对样本示例进行聚类(K=3)


```python
model = KMeans(n_clusters=3, random_state=2)
model.fit(X_s)
model.labels_
```

    array([1, 0, 2, 2, 2, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1], dtype=int32)

使用K=3的K均值聚类算法完成了聚类。结果显示，样本被分为三类，其中第2类数量最多（15个样本），第0类次之（9个样本），第1类最少（4个样本）。

```python
pd.DataFrame(model.labels_.T, index=data.V1,columns=['聚类'])
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>聚类</th>
    </tr>
    <tr>
      <th>V1</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>北京</th>
      <td>1</td>
    </tr>
    <tr>
      <th>天津</th>
      <td>0</td>
    </tr>
    <tr>
      <th>河北</th>
      <td>2</td>
    </tr>
    <tr>
      <th>山西</th>
      <td>2</td>
    </tr>
    <tr>
      <th>内蒙古</th>
      <td>2</td>
    </tr>
    <tr>
      <th>辽宁</th>
      <td>0</td>
    </tr>
    <tr>
      <th>黑龙江</th>
      <td>2</td>
    </tr>
    <tr>
      <th>江苏</th>
      <td>0</td>
    </tr>
    <tr>
      <th>浙江</th>
      <td>0</td>
    </tr>
    <tr>
      <th>安徽</th>
      <td>2</td>
    </tr>
    <tr>
      <th>福建</th>
      <td>0</td>
    </tr>
    <tr>
      <th>江西</th>
      <td>2</td>
    </tr>
    <tr>
      <th>山东</th>
      <td>0</td>
    </tr>
    <tr>
      <th>河南</th>
      <td>2</td>
    </tr>
    <tr>
      <th>湖北</th>
      <td>0</td>
    </tr>
    <tr>
      <th>湖南</th>
      <td>0</td>
    </tr>
    <tr>
      <th>广西</th>
      <td>2</td>
    </tr>
    <tr>
      <th>海南</th>
      <td>2</td>
    </tr>
    <tr>
      <th>重庆</th>
      <td>0</td>
    </tr>
    <tr>
      <th>四川</th>
      <td>0</td>
    </tr>
    <tr>
      <th>贵州</th>
      <td>2</td>
    </tr>
    <tr>
      <th>云南</th>
      <td>2</td>
    </tr>
    <tr>
      <th>西藏</th>
      <td>2</td>
    </tr>
    <tr>
      <th>陕西</th>
      <td>2</td>
    </tr>
    <tr>
      <th>甘肃</th>
      <td>2</td>
    </tr>
    <tr>
      <th>新疆</th>
      <td>2</td>
    </tr>
    <tr>
      <th>上海</th>
      <td>1</td>
    </tr>
    <tr>
      <th>广东</th>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>

按省份显示的聚类结果显示了更细致的分类：
- 第1类：北京、上海、广东（3个地区）- 商业规模最大
- 第0类：天津、辽宁、江苏、浙江、福建、山东、湖北、湖南、重庆、四川（9个地区）- 商业规模中等
- 第2类：河北、山西、内蒙古、黑龙江、安徽、江西、河南、广西、海南、贵州、云南、西藏、陕西、甘肃、新疆（15个地区）- 商业规模较小

这种分类反映了各地区商业发展的梯度特征，经济发达地区（如北京、上海、广东）明显领先，部分沿海和中部地区次之，西部和东北地区相对落后。

```python
np.set_printoptions(suppress=True)
model.cluster_centers_
```

    array([[ 0.03539069,  0.10060298,  0.10633798,  0.01837419],
           [ 2.64199186,  2.67740299,  2.64139452,  2.48929838],
           [-0.55199216, -0.60254925, -0.59917089, -0.51010914]])

三个聚类中心的坐标清晰地展示了梯度差异：
- 第1类中心：所有特征的标准化值均在2.4-2.7之间，远高于平均值
- 第0类中心：所有特征的标准化值接近0（约0.02-0.11之间），接近全国平均水平
- 第2类中心：所有特征的标准化值均为负值（约-0.51到-0.60之间），低于全国平均水平

```python
model.inertia_
```

    10.498603411717772

当K=3时，聚类的惯性值为10.499，比K=2时的20.197显著降低。这表明增加聚类数量有助于减小类内差异，提高聚类的紧密程度。

### 4.3 对样本示例进行聚类(K=4)


```python
model = KMeans(n_clusters=4, random_state=3)
model.fit(X_s)
model.labels_
```

    array([3, 0, 2, 2, 2, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1], dtype=int32)

使用K=4的K均值聚类算法完成了聚类。结果显示，样本被分为四类，其中第2类数量最多（15个样本），第0类次之（9个样本），第1类和第3类各有2个样本。

```python
pd.DataFrame(model.labels_.T, index=data.V1,columns=['聚类'])
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>聚类</th>
    </tr>
    <tr>
      <th>V1</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>北京</th>
      <td>3</td>
    </tr>
    <tr>
      <th>天津</th>
      <td>0</td>
    </tr>
    <tr>
      <th>河北</th>
      <td>2</td>
    </tr>
    <tr>
      <th>山西</th>
      <td>2</td>
    </tr>
    <tr>
      <th>内蒙古</th>
      <td>2</td>
    </tr>
    <tr>
      <th>辽宁</th>
      <td>0</td>
    </tr>
    <tr>
      <th>黑龙江</th>
      <td>2</td>
    </tr>
    <tr>
      <th>江苏</th>
      <td>0</td>
    </tr>
    <tr>
      <th>浙江</th>
      <td>0</td>
    </tr>
    <tr>
      <th>安徽</th>
      <td>2</td>
    </tr>
    <tr>
      <th>福建</th>
      <td>0</td>
    </tr>
    <tr>
      <th>江西</th>
      <td>2</td>
    </tr>
    <tr>
      <th>山东</th>
      <td>0</td>
    </tr>
    <tr>
      <th>河南</th>
      <td>2</td>
    </tr>
    <tr>
      <th>湖北</th>
      <td>0</td>
    </tr>
    <tr>
      <th>湖南</th>
      <td>0</td>
    </tr>
    <tr>
      <th>广西</th>
      <td>2</td>
    </tr>
    <tr>
      <th>海南</th>
      <td>2</td>
    </tr>
    <tr>
      <th>重庆</th>
      <td>0</td>
    </tr>
    <tr>
      <th>四川</th>
      <td>0</td>
    </tr>
    <tr>
      <th>贵州</th>
      <td>2</td>
    </tr>
    <tr>
      <th>云南</th>
      <td>2</td>
    </tr>
    <tr>
      <th>西藏</th>
      <td>2</td>
    </tr>
    <tr>
      <th>陕西</th>
      <td>2</td>
    </tr>
    <tr>
      <th>甘肃</th>
      <td>2</td>
    </tr>
    <tr>
      <th>新疆</th>
      <td>2</td>
    </tr>
    <tr>
      <th>上海</th>
      <td>1</td>
    </tr>
    <tr>
      <th>广东</th>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>

按省份显示的K=4聚类结果进一步细分了高规模群体：
- 第3类：仅北京（1个地区）- 商业规模最高
- 第1类：上海、广东（2个地区）- 商业规模次高
- 第0类：天津、辽宁、江苏、浙江、福建、山东、湖北、湖南、重庆、四川（9个地区）- 商业规模中等
- 第2类：河北、山西、内蒙古、黑龙江、安徽、江西、河南、广西、海南、贵州、云南、西藏、陕西、甘肃、新疆（15个地区）- 商业规模较小

这种分类将北京单独列为一类，表明北京在商业规模方面可能具有独特的领先地位，与上海和广东也存在一定差距。

```python
model.cluster_centers_
```

    array([[ 0.03539069,  0.10060298,  0.10633798,  0.01837419],
           [ 2.29731732,  2.6310961 ,  2.25936232,  1.7394465 ],
           [-0.55199216, -0.60254925, -0.59917089, -0.51010914],
           [ 3.33134093,  2.77001676,  3.40545892,  3.98900215]])

四个聚类中心的坐标详细展示了商业规模的梯度差异：
- 第3类中心（北京）：所有特征的标准化值都非常高，尤其是V9（统一配送商品购进额）达到3.99，显著高于其他地区
- 第1类中心（上海、广东）：所有特征的标准化值也较高（1.74-2.63之间），但低于北京
- 第0类中心：所有特征的标准化值接近0，保持在平均水平
- 第2类中心：所有特征的标准化值均为负值，低于平均水平

这种细分结果更好地反映了不同发达地区之间的差异。

```python
model.inertia_
```

    5.523575558087604

当K=4时，聚类的惯性值进一步降低至5.524，相比K=3时的10.499又减少了近一半。这表明增加聚类数量确实能提高聚类的紧密程度。从结果来看，K=4的聚类能够更细致地区分不同规模的商业群体。